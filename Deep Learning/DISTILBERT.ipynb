{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test = \"E:/Academics/IIT Bombay/aclImdb/test/\"\n",
    "train = \"E:/Academics/IIT Bombay/aclImdb/train/\"\n",
    "\n",
    "Test_list = []\n",
    "Train_list = []\n",
    "\n",
    "for i in ['pos','neg']:\n",
    "    \n",
    "    with os.scandir(test+i) as entries:\n",
    "        files = []\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                files += [entry.name]\n",
    "        for j in files:\n",
    "            ID = j.split('_')[0]\n",
    "            Label = (j.split('_')[1]).split('.')[0]\n",
    "            try:\n",
    "                with open(test+i+'/'+j,'r', encoding=\"utf8\") as t:\n",
    "                    Text = t.read()\n",
    "                if(i=='pos'):\n",
    "                    Test_list += [[ID, Text, Label, 1]]\n",
    "                else:\n",
    "                    Test_list += [[ID, Text, Label, 0]]\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    with os.scandir(train+i) as entries:\n",
    "        files = []\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                files += [entry.name]\n",
    "        for j in files:\n",
    "            ID = j.split('_')[0]\n",
    "            Label = (j.split('_')[1]).split('.')[0]\n",
    "            try:\n",
    "                with open(train+i+'/'+j,'r', encoding=\"utf8\") as t:\n",
    "                    Text = t.read()\n",
    "                if(i=='pos'):\n",
    "                    Train_list += [[ID, Text, Label, 1]]\n",
    "                else:\n",
    "                    Train_list += [[ID, Text, Label, 0]] \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "Train = pd.DataFrame(columns=['ID','Text','Label','Pos/Neg'],data = Train_list)\n",
    "Test  = pd.DataFrame(columns=['ID','Text','Label','Pos/Neg'],data = Test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split   \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(Train[['Text']], Train[['Label','Pos/Neg']], train_size = 0.8)\n",
    "x_test = Test[['Text']]\n",
    "y_test = Test[['Label','Pos/Neg']]\n",
    "\n",
    "x_train = list(x_train['Text'])\n",
    "x_test  = list(x_test['Text'])\n",
    "x_val   = list(x_val['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained( 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDatatype(Dataset):\n",
    "    \n",
    "    def __init__(self, X_d, X_p, y_data):\n",
    "        self.X_d = X_d\n",
    "        self.X_p = X_p\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #(torch.Tensor(self.X_data[index]['input_ids']), torch.Tensor(self.X_data[index]['attention_mask']))\n",
    "        return torch.Tensor(self.X_d[index]).to(torch.int64), torch.Tensor(self.X_p[index]).to(torch.int64), self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer(x_train,return_tensors='np', truncation=True, add_special_tokens=True, padding='max_length')\n",
    "x_test  = tokenizer(x_test, return_tensors='np', truncation=True, add_special_tokens=True, padding='max_length')\n",
    "x_val   = tokenizer(x_val, return_tensors='np', truncation=True, add_special_tokens=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = MyDatatype(x_train['input_ids'], x_train['attention_mask'], torch.Tensor(np.float32(y_train.to_numpy())))\n",
    "Test  = MyDatatype(x_test['input_ids'], x_test['attention_mask'], torch.Tensor(np.float32(y_train.to_numpy())))\n",
    "Valid = MyDatatype(x_val['input_ids'], x_val['attention_mask'], torch.Tensor(np.float32(y_train.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(dataset=Train, batch_size = batch_size,shuffle=True,drop_last=True)\n",
    "val_loader   = DataLoader(dataset=Valid, batch_size = batch_size,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooler(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        out = self.dense(first_token_tensor)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.base_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.bertpooler = Pooler(self.base_model.config)\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.linear = nn.Linear(self.base_model.config.hidden_size,2)\n",
    "        self.app1 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, xids, xmask):\n",
    "        x = self.base_model(input_ids = xids, attention_mask = xmask)\n",
    "        x = self.bertpooler(x.last_hidden_state)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.app1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuralNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (base_model): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bertpooler): Pooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (app1): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 52/1250 [11:30<4:23:15, 13.18s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 2\n",
    "model = NeuralNet()\n",
    "model.to(device)\n",
    "print(model)\n",
    "stats = []\n",
    "for e in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    stat = []\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    counter = 0\n",
    "    for X_inputs,X_attention, y_batch in tqdm(train_loader):\n",
    "        X_inputs,X_attention, y_batch = X_inputs.to(device), X_attention.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_inputs, X_attention)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        #if(counter%50)==0:\n",
    "            #print(f\"Done {counter} steps in epoch {e}\")\n",
    "    print(f'Epoch {e}: | Train_Loss: {epoch_loss/len(train_loader):.5f} | Train_Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    stat += [e,epoch_loss/len(train_loader),epoch_acc/len(train_loader)]    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_inputs,X_attention, y_batch in train_loader:\n",
    "        X_inputs,X_attention, y_batch = X_inputs.to(device), X_attention.to(device), y_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_inputs, X_attention)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    print(f'          | Valid_Loss: {epoch_loss/len(train_loader):.5f} | Valid_Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    stat += [epoch_loss/len(train_loader),epoch_acc/len(train_loader)]\n",
    "    stats += [stat]\n",
    "\n",
    "Stats = pd.DataFrame(columns=['Epoch','Train_Loss','Train_Accuracy', 'Validation_Loss','Validation_Accuracy'],data=stats)\n",
    "plt.plot(Stats['Epoch'], Stats['Train_Loss'],'r')\n",
    "plt.plot(Stats['Epoch'], Stats['Validation_Loss'],'g')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(f\"Losses\")\n",
    "plt.legend(['Train Loss','Validation Loss'])\n",
    "plt.show()\n",
    "plt.plot(Stats['Epoch'], Stats['Train_Accuracy'],'r')\n",
    "plt.plot(Stats['Epoch'], Stats['Validation_Accuracy'],'b')\n",
    "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(f\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe06f96167c4fc64a78c238d993189072a4e72b444216e36203d6f96126eaf0a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
